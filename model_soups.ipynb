{"cells":[{"cell_type":"code","source":"# Imports\nfrom flax import linen as nn\n\nimport jax\nimport optax\nimport flax\nimport jax.numpy as jnp\nfrom jax import jit\nfrom jax import lax\nfrom jax_resnet import pretrained_resnet, slice_variables, Sequential\nfrom flax.jax_utils import replicate, unreplicate\nfrom flax.training import train_state, checkpoints\nfrom flax import linen as nn\nfrom flax.core import FrozenDict,frozen_dict\nfrom flax.training.common_utils import shard","metadata":{"tags":[],"cell_id":"94a2fe9b21724cc5aedc2f0b837e2d28","source_hash":"ebb5d38a","execution_start":1669847943098,"execution_millis":9707,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n2022-11-30 22:39:05.770981: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2022-11-30 22:39:05.872565: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2022-11-30 22:39:08.891330: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2022-11-30 22:39:08.891391: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2022-11-30 22:39:08.891397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#Get logits given state\ndef get_logits(state):\n    logits = []\n    iter_n = len(test_dataset)\n    with tqdm(total=iter_n, desc=f\"{iter_n} iterations\", leave=False) as progress_bar:\n        for _batch in test_dataset:\n            batch = _batch[0]\n            labels = _batch[1]\n\n            batch = jnp.array(batch, dtype=jnp.float32)\n            labels = jnp.array(labels, dtype=jnp.float32)\n\n            batch, labels = shard(batch), shard(labels)\n            metric = parallel_val_step(state, batch, labels)[0]\n            valid_accuracy.append(metric)\n            progress_bar.update(1)\n            del(batch)\n            del(labels)    \n\n# Get validation accuracy given state\nparallel_val_step = jax.pmap(val_step, axis_name='batch', donate_argnums=(0,))\ndef get_valid_acc(state):\n    valid_accuracy = []\n    iter_n = len(test_dataset)\n    with tqdm(total=iter_n, desc=f\"{iter_n} iterations\", leave=False) as progress_bar:\n        for _batch in test_dataset:\n            batch = _batch[0]\n            labels = _batch[1]\n\n            batch = jnp.array(batch, dtype=jnp.float32)\n            labels = jnp.array(labels, dtype=jnp.float32)\n\n            batch, labels = shard(batch), shard(labels)\n            metric = parallel_val_step(state, batch, labels)[0]\n            valid_accuracy.append(metric)\n            progress_bar.update(1)\n            del(batch)\n            del(labels)\n\n    avg_valid_acc = sum(valid_accuracy)/len(valid_accuracy)\n    avg_valid_acc = np.array(avg_valid_acc)[0]\n    valid_acc.append(avg_valid_acc)\n    print(f\"[{epoch_i+1}/{Config['N_EPOCHS']}] Valid Accuracy: {avg_valid_acc:.03}\")\n    return avg_valid_acc ","metadata":{"tags":[],"cell_id":"b87c4b0e4dfa43cab171795ca7cc48c9","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load in the fine-tuned models\ndef create_train_state(model, variables, optimizer):\n  state = TrainState.create(\n      apply_fn = model.apply,\n      params = variables['params'],\n      tx = optimizer,\n      batch_stats = variables['batch_stats'],\n      loss_fn = loss_fn,\n      eval_fn = eval_fn\n  )\n  \n  return state\n\nstates = []\nfor i in range(k):\n    model, variables = get_model_and_variables('resnet18', 0)\n    state_dict = checkpoints.restore_checkpoint(f'model_{i}', target=None)\n    state = create_train_state(model, state_dict, None)\n    states.append(state)","metadata":{"tags":[],"cell_id":"fdd9f89a7b904efcaff9665803eff2ad","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get all the state accuracies \ndef state_accs(states):\n    accs = []\n    ### BEGIN CODE HERE ###\n    for state in states:\n        accs.append(get_valid_acc(state))  \n    ### END CODE HERE ##\n    return accs","metadata":{"tags":[],"cell_id":"692227f67e424c53873157e5ff5a755f","source_hash":"e7663177","execution_start":1669847873419,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Graph all the model accuracies (label the best one)\nvalid_accs = state_accs(states)\n\nnames = [f'Model {i+1}' for i in range(len(states))]\nplt.bar(names, valid_accs)\nplt.title(\"Validation Accuracy By Model\")\nplt.ylim([0.95,1])\nplt.xticks(rotation=30, ha='right')","metadata":{"tags":[],"cell_id":"6287a0ce0530490a8be9192f206b06e1","source_hash":"cbcf4924","execution_start":1669847874762,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'states' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Graph all the model accuracies (label the best one)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m valid_accs \u001b[38;5;241m=\u001b[39m state_accs(\u001b[43mstates\u001b[49m)\n\u001b[1;32m      4\u001b[0m names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(states))]\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(names, valid_accs)\n","\u001b[0;31mNameError\u001b[0m: name 'states' is not defined"]}],"execution_count":5},{"cell_type":"markdown","source":"## Ensemble Learning: Average the logits of the models","metadata":{"tags":[],"cell_id":"712de6f1ed6f4a688de9d28d1213f488","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"# get ensemble learning accruacy \ndef ensemble_acc(states):\n    acc = None\n    for state in states: \n    ### BEGIN CODE HERE ###\n        \n    ### END CODE HERE ###\n    return acc","metadata":{"tags":[],"cell_id":"e7bbeb6b81944f7c92b1592ae2fdaa66","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Graph the validation accuracy of ensemble model vs individual models\n\nnames = [f'Model {i+1}' for i in range(len(states) + 1)]\nplt.bar(names, valid_accs)\nplt.title(\"Validation Accuracy \")\nplt.ylim([0.8,1])\nplt.xticks(rotation=30, ha='right')","metadata":{"tags":[],"cell_id":"77ee5edfdc2748e6b178fe6d2c1075b1","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Question: Why do you think the ensemble output has better accuracy than the single models?","metadata":{"tags":[],"cell_id":"3585059034f940f292bdb2b48fa2792d","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Answer: ","metadata":{"tags":[],"cell_id":"70dbcf42852b4827ad99b058facece76","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"## Uniform Soup: Uniformly","metadata":{"tags":[],"cell_id":"3c5d8980579e4766ac518b6a5b6982fd","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"# Return model with weights averaged according to alphas\ndef get_model(states, alphas):\n    # model, _ = clip.load('ViT-B/32')\n    # feature_dim = state_dicts[0]['classification_head.weight'].shape[1]\n    # num_classes = state_dicts[0]['classification_head.weight'].shape[0]\n    # normalize = True\n    # model = ModelWrapper(model, feature_dim, num_classes, normalize)\n    states.param\n\n    sd = {k : states.params[k] * alphal[0] for k in state_dicts[0].keys()}\n    for i in range(1, len(state_dicts)):\n        for k in state_dicts[i].keys():\n            sd[k] = sd[k] + state_dicts[i][k].clone() * alphal[i]\n\n    model.load_state_dict(sd)\n    model = model.to(device)\n    return model","metadata":{"tags":[],"cell_id":"f66de11fab97487bbd37ff556a95c73a","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def uniform_soup:\n    ","metadata":{"tags":[],"cell_id":"28f7b17b93b74a7f9dfaa0416799af2f","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Greedy Soup Implementation","metadata":{"tags":[],"cell_id":"19ddeb6658784d568b56d3784dde4d07","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"Question: Why does greedy soup perform better than uniform? Do you think this is always the case?","metadata":{"tags":[],"cell_id":"80dd067c9f4f48a0942c4e2b0ef9c02b","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Answer: ","metadata":{"tags":[],"cell_id":"172f18bfe0af4b478cab8e6fa293f5d7","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Question: What are the benefits of souping vs traditional ensemble methods in terms of space and time complexity?","metadata":{"tags":[],"cell_id":"669a9dbf25a14eaf9642abb7638c066a","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"Answer: ","metadata":{"tags":[],"cell_id":"4b323d967eb549f38341038fd1a60903","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"## Learned Soup Implementation","metadata":{"tags":[],"cell_id":"d66fdf3fa21f486486a7bbb2fa8bf7c3","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a527420b-c11f-44a4-82a9-68959d523a68' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"9ed94c2a8ddc4843ad3f8ef202fbcb7b","deepnote_execution_queue":[]}}